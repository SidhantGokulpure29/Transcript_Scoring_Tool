{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Description:**\n",
        "\n",
        "As part of our Communication Program, we are building an AI tool to analyse and score studentsâ€™ spoken communication skills. One common exercise is a short self-introduction submitted as an audio file. The audio has already been transcribed to text (transcript provided in the Excel file).\n",
        "\n",
        "Objective of this case study: build a tool (front-end + back-end+ Logics) that takes a transcript text as input and produces a rubric-based final score (0â€“100) and per-criterion feedback. The tool must combine rule-based methods, NLP-based semantic scoring, and apply the data driven rubric provided in the Excel file."
      ],
      "metadata": {
        "id": "5mzKiCjemfzU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Environment Setup: Installing Libraries**"
      ],
      "metadata": {
        "id": "nVL9M53tned7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9noNkrol3qQ",
        "outputId": "01bbd278-ec3d-4314-ecd4-d1b4202510e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit==1.38.0 in /usr/local/lib/python3.12/dist-packages (1.38.0)\n",
            "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
            "Requirement already satisfied: openpyxl==3.1.5 in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: regex==2024.9.11 in /usr/local/lib/python3.12/dist-packages (2024.9.11)\n",
            "Requirement already satisfied: sentence-transformers==3.0.1 in /usr/local/lib/python3.12/dist-packages (3.0.1)\n",
            "Requirement already satisfied: scikit-learn==1.4.2 in /usr/local/lib/python3.12/dist-packages (1.4.2)\n",
            "Requirement already satisfied: language-tool-python==2.7.1 in /usr/local/lib/python3.12/dist-packages (2.7.1)\n",
            "Requirement already satisfied: vaderSentiment==3.3.2 in /usr/local/lib/python3.12/dist-packages (3.3.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (8.3.1)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (24.2)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (10.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (2.32.4)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (13.9.4)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (4.15.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (6.5.1)\n",
            "Requirement already satisfied: watchdog<5,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit==1.38.0) (4.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl==3.1.5) (2.0.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==3.0.1) (4.57.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==3.0.1) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==3.0.1) (2.9.0+cu126)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==3.0.1) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==3.0.1) (0.36.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.4.2) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.4.2) (3.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair<6,>=4.0->streamlit==1.38.0) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair<6,>=4.0->streamlit==1.38.0) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair<6,>=4.0->streamlit==1.38.0) (2.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.38.0) (4.0.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==3.0.1) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==3.0.1) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==3.0.1) (6.0.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==3.0.1) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit==1.38.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit==1.38.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit==1.38.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit==1.38.0) (2025.11.12)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich<14,>=10.14.0->streamlit==1.38.0) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich<14,>=10.14.0->streamlit==1.38.0) (2.19.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (3.5.0)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers==3.0.1) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers==3.0.1) (0.7.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.38.0) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair<6,>=4.0->streamlit==1.38.0) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.38.0) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.38.0) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.38.0) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.38.0) (0.29.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit==1.38.0) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers==3.0.1) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit==1.38.0 pandas==2.2.2 numpy==1.26.4 openpyxl==3.1.5 regex==2024.9.11 \\\n",
        "sentence-transformers==3.0.1 scikit-learn==1.4.2 language-tool-python==2.7.1 vaderSentiment==3.3.2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Rubric Loader**"
      ],
      "metadata": {
        "id": "85LYQ12GoCJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This block defines all rubric criteria directly in Python, based on the Excel and image rubrics.\n",
        "# Each criterion includes: criterion, description, keywords (if applicable), and weight.\n",
        "\n",
        "rubric_data = [\n",
        "    {\n",
        "        \"criterion\": \"Salutation Level\",\n",
        "        \"description\": \"Quality of greeting at the start of introduction\",\n",
        "        \"keywords\": [\"hi\", \"hello\", \"good morning\", \"good afternoon\", \"good evening\", \"good day\", \"hello everyone\", \"i am excited to introduce\", \"feeling great\"],\n",
        "        \"weight\": 5\n",
        "    },\n",
        "    {\n",
        "        \"criterion\": \"Keyword Presence\",\n",
        "        \"description\": \"Presence of mandatory and optional details: name, age, class, school, family, hobbies, goals, unique point\",\n",
        "        \"keywords\": [\n",
        "            # Must-have (4 points each)\n",
        "            \"name\", \"age\", \"class\", \"school\", \"family\", \"hobbies\", \"interest\", \"free time\",\n",
        "            # Good-to-have (2 points each)\n",
        "            \"about family\", \"i am from\", \"parents are from\", \"ambition\", \"goal\", \"dream\", \"fun fact\", \"unique\", \"strength\", \"achievement\"\n",
        "        ],\n",
        "        \"weight\": 30\n",
        "    },\n",
        "    {\n",
        "        \"criterion\": \"Flow\",\n",
        "        \"description\": \"Order followed: Salutation â†’ Basic details â†’ Additional details â†’ Closing\",\n",
        "        \"keywords\": [\"salutation\", \"basic details\", \"additional details\", \"closing\"],\n",
        "        \"weight\": 5\n",
        "    },\n",
        "    {\n",
        "        \"criterion\": \"Speech Rate\",\n",
        "        \"description\": \"Words per minute (WPM) speed of speaking\",\n",
        "        \"keywords\": [],\n",
        "        \"weight\": 10\n",
        "    },\n",
        "    {\n",
        "        \"criterion\": \"Grammar\",\n",
        "        \"description\": \"Grammar correctness using LanguageTool\",\n",
        "        \"keywords\": [],\n",
        "        \"weight\": 10\n",
        "    },\n",
        "    {\n",
        "        \"criterion\": \"Vocabulary Richness\",\n",
        "        \"description\": \"Lexical diversity measured by TTR (Type-Token Ratio)\",\n",
        "        \"keywords\": [],\n",
        "        \"weight\": 10\n",
        "    },\n",
        "    {\n",
        "        \"criterion\": \"Clarity\",\n",
        "        \"description\": \"Filler word rate (um, uh, like, you know, etc.)\",\n",
        "        \"keywords\": [\"um\", \"uh\", \"like\", \"you know\", \"so\", \"actually\", \"basically\", \"right\", \"i mean\", \"well\", \"kinda\", \"sort of\", \"okay\", \"hmm\", \"ah\"],\n",
        "        \"weight\": 15\n",
        "    },\n",
        "    {\n",
        "        \"criterion\": \"Engagement\",\n",
        "        \"description\": \"Sentiment/positivity of transcript using VADER\",\n",
        "        \"keywords\": [],\n",
        "        \"weight\": 15\n",
        "    }\n",
        "]\n",
        "\n",
        "# Quick check: print all criteria and weights\n",
        "for r in rubric_data:\n",
        "    print(f\"{r['criterion']:25} â†’ weight: {r['weight']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAkU1JWDoDmz",
        "outputId": "ecb75367-a19c-49de-9e94-ee500cb1b979"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Salutation Level          â†’ weight: 5\n",
            "Keyword Presence          â†’ weight: 30\n",
            "Flow                      â†’ weight: 5\n",
            "Speech Rate               â†’ weight: 10\n",
            "Grammar                   â†’ weight: 10\n",
            "Vocabulary Richness       â†’ weight: 10\n",
            "Clarity                   â†’ weight: 15\n",
            "Engagement                â†’ weight: 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Transcript Processing**"
      ],
      "metadata": {
        "id": "cBUVEex8-dlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This block cleans the transcript, counts words and sentences, and detects filler words.\n",
        "\n",
        "import re\n",
        "\n",
        "# Define filler words from rubric\n",
        "FILLER_WORDS = set([\n",
        "    \"um\", \"uh\", \"like\", \"you know\", \"so\", \"actually\", \"basically\", \"right\",\n",
        "    \"i mean\", \"well\", \"kinda\", \"sort of\", \"okay\", \"hmm\", \"ah\"\n",
        "])\n",
        "\n",
        "def preprocess_transcript(text: str):\n",
        "\n",
        "    # Normalize text\n",
        "    cleaned = text.lower().strip()\n",
        "    cleaned = re.sub(r\"\\s+\", \" \", cleaned)  # collapse whitespace\n",
        "    cleaned = re.sub(r\"[^\\w\\s]\", \"\", cleaned)  # remove punctuation\n",
        "\n",
        "    # Word and sentence counts\n",
        "    words = cleaned.split()\n",
        "    word_count = len(words)\n",
        "    sentence_count = text.count(\".\") + text.count(\"!\") + text.count(\"?\")  # rough estimate\n",
        "\n",
        "    # Filler word detection\n",
        "    filler_hits = [w for w in words if w in FILLER_WORDS]\n",
        "    filler_count = len(filler_hits)\n",
        "    filler_rate = round((filler_count / word_count) * 100, 2) if word_count > 0 else 0\n",
        "\n",
        "    return {\n",
        "        \"cleaned_text\": cleaned,\n",
        "        \"word_count\": word_count,\n",
        "        \"sentence_count\": sentence_count,\n",
        "        \"filler_count\": filler_count,\n",
        "        \"filler_rate\": filler_rate,\n",
        "        \"filler_words_found\": filler_hits\n",
        "    }\n",
        "\n",
        "sample_text = \"\"\"Hello everyone, myself Muskan, studying in class 8th B section from Christ Public School.\n",
        "I am 13 years old. I live with my family. There are 3 people in my family, me, my mother and my father.\n",
        "One special thing about my family is that they are very kind hearted to everyone and soft spoken. One thing I really enjoy is play, playing cricket and taking wickets.\n",
        "A fun fact about me is that I see in mirror and talk by myself. One thing people don't know about me is that I once stole a toy from one of my cousin.\n",
        "My favorite subject is science because it is very interesting. Through science I can explore the whole world and make the discoveries and improve the lives of others.\n",
        "Thank you for listening.\"\"\"\n",
        "\n",
        "preprocessed = preprocess_transcript(sample_text)\n",
        "print(preprocessed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rohlL6oH-dGx",
        "outputId": "2c006643-47ec-4c44-e355-412be6e5df3a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'cleaned_text': 'hello everyone myself muskan studying in class 8th b section from christ public school i am 13 years old i live with my family there are 3 people in my family me my mother and my father one special thing about my family is that they are very kind hearted to everyone and soft spoken one thing i really enjoy is play playing cricket and taking wickets a fun fact about me is that i see in mirror and talk by myself one thing people dont know about me is that i once stole a toy from one of my cousin my favorite subject is science because it is very interesting through science i can explore the whole world and make the discoveries and improve the lives of others thank you for listening', 'word_count': 133, 'sentence_count': 11, 'filler_count': 0, 'filler_rate': 0.0, 'filler_words_found': []}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Salutation and Keyword Scoring**"
      ],
      "metadata": {
        "id": "-zrKzD0vH7Tj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This block scores two rule-based criteria:\n",
        "# - Salutation Level: based on greeting phrases\n",
        "# - Keyword Presence: checks for must-have and good-to-have keywords\n",
        "\n",
        "def score_salutation(text: str):\n",
        "    \"\"\"\n",
        "    Score salutation level based on presence of greeting phrases.\n",
        "    Returns score (0â€“5) and matched phrase.\n",
        "    \"\"\"\n",
        "    text_lower = text.lower()\n",
        "    if \"i am excited to introduce\" in text_lower or \"feeling great\" in text_lower:\n",
        "        return 5, \"Excellent\"\n",
        "    elif any(phrase in text_lower for phrase in [\"good morning\", \"good afternoon\", \"good evening\", \"good day\", \"hello everyone\"]):\n",
        "        return 4, \"Good\"\n",
        "    elif any(phrase in text_lower for phrase in [\"hi\", \"hello\"]):\n",
        "        return 2, \"Normal\"\n",
        "    else:\n",
        "        return 0, \"No Salutation\"\n",
        "\n",
        "def score_keywords(text: str):\n",
        "    \"\"\"\n",
        "    Score keyword presence based on must-have and good-to-have keywords.\n",
        "    Returns score (0â€“30), list of matched keywords, and missing ones.\n",
        "    \"\"\"\n",
        "    text_lower = text.lower()\n",
        "    words = set(text_lower.split())\n",
        "\n",
        "    # Define must-have (4 pts each) and good-to-have (2 pts each)\n",
        "    must_have = [\"name\", \"age\", \"class\", \"school\", \"family\", \"hobbies\", \"interest\", \"free time\"]\n",
        "    good_to_have = [\"about family\", \"i am from\", \"parents are from\", \"ambition\", \"goal\", \"dream\", \"fun fact\", \"unique\", \"strength\", \"achievement\"]\n",
        "\n",
        "    score = 0\n",
        "    matched = []\n",
        "    missing = []\n",
        "\n",
        "    # Check must-have\n",
        "    for kw in must_have:\n",
        "        if kw in text_lower:\n",
        "            score += 4\n",
        "            matched.append(kw)\n",
        "        else:\n",
        "            missing.append(kw)\n",
        "\n",
        "    # Check good-to-have\n",
        "    for kw in good_to_have:\n",
        "        if kw in text_lower:\n",
        "            score += 2\n",
        "            matched.append(kw)\n",
        "        else:\n",
        "            missing.append(kw)\n",
        "\n",
        "    # Cap score at 30\n",
        "    score = min(score, 30)\n",
        "\n",
        "    return score, matched, missing\n",
        "\n",
        "# Example usage:\n",
        "sal_score, sal_type = score_salutation(sample_text)\n",
        "kw_score, kw_matched, kw_missing = score_keywords(sample_text)\n",
        "\n",
        "print(f\"Salutation Score: {sal_score} ({sal_type})\")\n",
        "print(f\"Keyword Score: {kw_score}\")\n",
        "print(f\"Matched Keywords: {kw_matched}\")\n",
        "print(f\"Missing Keywords: {kw_missing}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JckmeqQ9H_qr",
        "outputId": "41472ada-021d-481b-802a-b835abca3718"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Salutation Score: 4 (Good)\n",
            "Keyword Score: 18\n",
            "Matched Keywords: ['class', 'school', 'family', 'interest', 'fun fact']\n",
            "Missing Keywords: ['name', 'age', 'hobbies', 'free time', 'about family', 'i am from', 'parents are from', 'ambition', 'goal', 'dream', 'unique', 'strength', 'achievement']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Flow Scoring**"
      ],
      "metadata": {
        "id": "7I_9y1VmLQ1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This block checks whether the transcript follows the expected order:\n",
        "# Salutation â†’ Basic Details â†’ Additional Details â†’ Closing\n",
        "\n",
        "def score_flow(text: str):\n",
        "    \"\"\"\n",
        "    Score flow based on presence and order of key sections.\n",
        "    Returns score (0 or 5) and detected order.\n",
        "    \"\"\"\n",
        "    text_lower = text.lower()\n",
        "\n",
        "    # Define section anchors\n",
        "    salutation_phrases = [\"hello\", \"hi\", \"good morning\", \"good afternoon\", \"good evening\", \"i am excited\"]\n",
        "    basic_details = [\"my name is\", \"i am\", \"class\", \"school\", \"age\"]\n",
        "    additional_details = [\"hobbies\", \"interest\", \"fun fact\", \"goal\", \"dream\", \"unique\", \"strength\", \"achievement\"]\n",
        "    closing_phrases = [\"thank you\", \"thanks for listening\", \"that's all\"]\n",
        "\n",
        "    # Find positions of each section\n",
        "    def find_first(text, phrases):\n",
        "        for phrase in phrases:\n",
        "            idx = text.find(phrase)\n",
        "            if idx != -1:\n",
        "                return idx\n",
        "        return -1\n",
        "\n",
        "    sal_idx = find_first(text_lower, salutation_phrases)\n",
        "    basic_idx = find_first(text_lower, basic_details)\n",
        "    add_idx = find_first(text_lower, additional_details)\n",
        "    close_idx = find_first(text_lower, closing_phrases)\n",
        "\n",
        "    # Check if order is followed\n",
        "    positions = [sal_idx, basic_idx, add_idx, close_idx]\n",
        "    valid_positions = [p for p in positions if p != -1]\n",
        "\n",
        "    if valid_positions == sorted(valid_positions):\n",
        "        return 5, \"Order followed\"\n",
        "    else:\n",
        "        return 0, \"Order not followed\"\n",
        "\n",
        "# Example usage:\n",
        "flow_score, flow_feedback = score_flow(sample_text)\n",
        "print(f\"Flow Score: {flow_score} ({flow_feedback})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmfcVHgcLTYF",
        "outputId": "8c9fc11a-3911-42fc-a807-f98e0ef365dc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flow Score: 5 (Order followed)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Speech Rate Scoring**"
      ],
      "metadata": {
        "id": "RHCIU8PTM91Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This block calculates words per minute (WPM) and assigns a score based on rubric thresholds.\n",
        "\n",
        "def score_speech_rate(word_count: int, duration_sec: int):\n",
        "\n",
        "    if duration_sec <= 0:\n",
        "        return 0, 0, \"Invalid duration\"\n",
        "\n",
        "    wpm = (word_count / duration_sec) * 60  # words per minute\n",
        "\n",
        "    # Apply rubric thresholds\n",
        "    if wpm > 161:\n",
        "        return 2, round(wpm, 2), \"Too Fast\"\n",
        "    elif 141 <= wpm <= 160:\n",
        "        return 6, round(wpm, 2), \"Fast\"\n",
        "    elif 111 <= wpm <= 140:\n",
        "        return 10, round(wpm, 2), \"Ideal\"\n",
        "    elif 81 <= wpm <= 110:\n",
        "        return 6, round(wpm, 2), \"Slow\"\n",
        "    elif wpm < 80:\n",
        "        return 2, round(wpm, 2), \"Too Slow\"\n",
        "    else:\n",
        "        return 0, round(wpm, 2), \"Unscored\"\n",
        "\n",
        "# Example usage:\n",
        "duration_sec = 52  # from rubric sample\n",
        "speech_score, wpm_value, wpm_category = score_speech_rate(preprocessed[\"word_count\"], duration_sec)\n",
        "\n",
        "print(f\"Speech Rate Score: {speech_score} ({wpm_category}, {wpm_value} WPM)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rifbussfNAPG",
        "outputId": "e266bacb-1979-435c-9565-745c8b8e58a1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech Rate Score: 6 (Fast, 153.46 WPM)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Grammar Scoring**"
      ],
      "metadata": {
        "id": "pCckg9okOo7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# - Detect repeated words\n",
        "# - Detect missing capitalization at sentence start\n",
        "# - Detect very long sentences (run-ons)\n",
        "\n",
        "import re\n",
        "\n",
        "def score_grammar_simple(text: str):\n",
        "\n",
        "    words = text.split()\n",
        "    word_count = len(words)\n",
        "\n",
        "    # Heuristic 1: repeated words\n",
        "    repeated_errors = sum(1 for i in range(1, len(words)) if words[i].lower() == words[i-1].lower())\n",
        "\n",
        "    # Heuristic 2: sentences not starting with capital letter\n",
        "    sentences = re.split(r'[.!?]', text)\n",
        "    capitalization_errors = sum(1 for s in sentences if s.strip() and not s.strip()[0].isupper())\n",
        "\n",
        "    # Heuristic 3: very long sentences (>30 words)\n",
        "    long_sentence_errors = sum(1 for s in sentences if len(s.split()) > 30)\n",
        "\n",
        "    error_count = repeated_errors + capitalization_errors + long_sentence_errors\n",
        "\n",
        "    # Errors per 100 words\n",
        "    errors_per_100 = (error_count / word_count) * 100 if word_count > 0 else 0\n",
        "\n",
        "    # Grammar score formula (same as rubric)\n",
        "    grammar_score_ratio = 1 - min(errors_per_100 / 10, 1)\n",
        "\n",
        "    # Map to rubric bands\n",
        "    if grammar_score_ratio > 0.9:\n",
        "        score = 10\n",
        "    elif 0.7 <= grammar_score_ratio <= 0.89:\n",
        "        score = 8\n",
        "    elif 0.5 <= grammar_score_ratio <= 0.69:\n",
        "        score = 6\n",
        "    elif 0.3 <= grammar_score_ratio <= 0.49:\n",
        "        score = 4\n",
        "    else:\n",
        "        score = 2\n",
        "\n",
        "    return score, error_count, grammar_score_ratio\n",
        "\n",
        "grammar_score, grammar_errors, grammar_ratio = score_grammar_simple(sample_text)\n",
        "print(f\"Grammar Score: {grammar_score} (Errors: {grammar_errors}, Ratio: {grammar_ratio:.2f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPf_QypnOrUH",
        "outputId": "da2eb6fc-0d4f-4ac5-db74-6d988163a961"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grammar Score: 10 (Errors: 0, Ratio: 1.00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Vocabulary Richness Scoring**"
      ],
      "metadata": {
        "id": "poIZe_X2aN4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This block calculates lexical diversity using Type-Token Ratio (TTR).\n",
        "\n",
        "def score_vocabulary(text: str):\n",
        "    \"\"\"\n",
        "    Calculate vocabulary richness using TTR (Type-Token Ratio).\n",
        "    Returns score (2â€“10), TTR value, and category.\n",
        "    \"\"\"\n",
        "    words = text.lower().split()\n",
        "    total_words = len(words)\n",
        "    distinct_words = len(set(words))\n",
        "\n",
        "    if total_words == 0:\n",
        "        return 0, 0, \"No words\"\n",
        "\n",
        "    ttr = distinct_words / total_words\n",
        "\n",
        "    if 0.9 <= ttr <= 1.0:\n",
        "        score = 10\n",
        "        category = \"Excellent\"\n",
        "    elif 0.7 <= ttr <= 0.89:\n",
        "        score = 8\n",
        "        category = \"Good\"\n",
        "    elif 0.5 <= ttr <= 0.69:\n",
        "        score = 6\n",
        "        category = \"Average\"\n",
        "    elif 0.3 <= ttr <= 0.49:\n",
        "        score = 4\n",
        "        category = \"Poor\"\n",
        "    else:  # 0â€“0.29\n",
        "        score = 2\n",
        "        category = \"Very Poor\"\n",
        "\n",
        "    return score, round(ttr, 2), category\n",
        "\n",
        "vocab_score, vocab_ttr, vocab_category = score_vocabulary(sample_text)\n",
        "print(f\"Vocabulary Score: {vocab_score} ({vocab_category}, TTR={vocab_ttr})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeFVM4snaQsq",
        "outputId": "ec068dc9-29d8-4e78-a38f-5c27f226cfb2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Score: 6 (Average, TTR=0.68)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Clarity Scoring**"
      ],
      "metadata": {
        "id": "eCgdie7Jaqb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This block calculates filler word rate and assigns a score based on rubric thresholds.\n",
        "\n",
        "def score_clarity(preprocessed: dict):\n",
        "    \"\"\"\n",
        "    Calculate clarity score based on filler word rate.\n",
        "    Returns score (3â€“15), filler count, filler rate, and category.\n",
        "    \"\"\"\n",
        "    filler_count = preprocessed[\"filler_count\"]\n",
        "    filler_rate = preprocessed[\"filler_rate\"]\n",
        "\n",
        "    # Apply rubric thresholds\n",
        "    if filler_rate <= 3:\n",
        "        score = 15\n",
        "        category = \"Excellent\"\n",
        "    elif 4 <= filler_rate <= 6:\n",
        "        score = 12\n",
        "        category = \"Good\"\n",
        "    elif 7 <= filler_rate <= 9:\n",
        "        score = 9\n",
        "        category = \"Average\"\n",
        "    elif 10 <= filler_rate <= 12:\n",
        "        score = 6\n",
        "        category = \"Poor\"\n",
        "    else:  # 13% and above\n",
        "        score = 3\n",
        "        category = \"Very Poor\"\n",
        "\n",
        "    return score, filler_count, filler_rate, category\n",
        "\n",
        "clarity_score, filler_count, filler_rate, clarity_category = score_clarity(preprocessed)\n",
        "print(f\"Clarity Score: {clarity_score} ({clarity_category}, {filler_count} fillers, {filler_rate}% rate)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-eKQ57uar6-",
        "outputId": "f49260d3-c870-48cd-cd2d-5416dcb86680"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clarity Score: 15 (Excellent, 0 fillers, 0.0% rate)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Engagement Scoring using VADER**"
      ],
      "metadata": {
        "id": "ffWK0uXkbMNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This block uses VADER sentiment analysis to measure positivity and assign engagement score.\n",
        "\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "def score_engagement(text: str):\n",
        "    \"\"\"\n",
        "    Calculate engagement score using VADER sentiment positivity.\n",
        "    Returns score (3â€“15), positivity value, and category.\n",
        "    \"\"\"\n",
        "    sentiment = analyzer.polarity_scores(text)\n",
        "    positivity = sentiment[\"pos\"]  # probability of positive sentiment (0â€“1)\n",
        "\n",
        "    if positivity >= 0.9:\n",
        "        score = 15\n",
        "        category = \"Highly Positive\"\n",
        "    elif 0.7 <= positivity <= 0.89:\n",
        "        score = 12\n",
        "        category = \"Positive\"\n",
        "    elif 0.5 <= positivity <= 0.69:\n",
        "        score = 9\n",
        "        category = \"Neutral/Moderate\"\n",
        "    elif 0.3 <= positivity <= 0.49:\n",
        "        score = 6\n",
        "        category = \"Low Positive\"\n",
        "    else:  # <0.3\n",
        "        score = 3\n",
        "        category = \"Negative/Disengaged\"\n",
        "\n",
        "    return score, positivity, category\n",
        "\n",
        "engagement_score, positivity_value, engagement_category = score_engagement(sample_text)\n",
        "print(f\"Engagement Score: {engagement_score} ({engagement_category}, Positivity={positivity_value:.2f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12nEFxhebPEO",
        "outputId": "f2950ad2-37b0-441e-f539-9ddaf1023f73"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Engagement Score: 3 (Negative/Disengaged, Positivity=0.19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Final Score**"
      ],
      "metadata": {
        "id": "U9-FDGnDbhH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This block aggregates all rubric scores into a weighted total and prints a detailed breakdown.\n",
        "\n",
        "def evaluate_transcript(text: str, duration_sec: int):\n",
        "\n",
        "    # Preprocess\n",
        "    prep = preprocess_transcript(text)\n",
        "\n",
        "    sal_score, sal_type = score_salutation(text)\n",
        "    kw_score, kw_matched, kw_missing = score_keywords(text)\n",
        "    flow_score, flow_feedback = score_flow(text)\n",
        "    speech_score, wpm_value, wpm_category = score_speech_rate(prep[\"word_count\"], duration_sec)\n",
        "    grammar_score, grammar_errors, grammar_ratio = score_grammar_simple(text)\n",
        "    vocab_score, vocab_ttr, vocab_category = score_vocabulary(text)\n",
        "    clarity_score, filler_count, filler_rate, clarity_category = score_clarity(prep)\n",
        "    engagement_score, positivity_value, engagement_category = score_engagement(text)\n",
        "\n",
        "    # Weighted total (weights from rubric_data)\n",
        "    total_score = (\n",
        "        sal_score +\n",
        "        kw_score +\n",
        "        flow_score +\n",
        "        speech_score +\n",
        "        grammar_score +\n",
        "        vocab_score +\n",
        "        clarity_score +\n",
        "        engagement_score\n",
        "    )\n",
        "\n",
        "    # Build report\n",
        "    report = {\n",
        "        \"Salutation\": {\"score\": sal_score, \"type\": sal_type},\n",
        "        \"Keywords\": {\"score\": kw_score, \"matched\": kw_matched, \"missing\": kw_missing},\n",
        "        \"Flow\": {\"score\": flow_score, \"feedback\": flow_feedback},\n",
        "        \"Speech Rate\": {\"score\": speech_score, \"wpm\": wpm_value, \"category\": wpm_category},\n",
        "        \"Grammar\": {\"score\": grammar_score, \"errors\": grammar_errors, \"ratio\": round(grammar_ratio, 2)},\n",
        "        \"Vocabulary\": {\"score\": vocab_score, \"ttr\": vocab_ttr, \"category\": vocab_category},\n",
        "        \"Clarity\": {\"score\": clarity_score, \"fillers\": filler_count, \"rate\": filler_rate, \"category\": clarity_category},\n",
        "        \"Engagement\": {\"score\": engagement_score, \"positivity\": round(positivity_value, 2), \"category\": engagement_category},\n",
        "        \"Total Score\": total_score\n",
        "    }\n",
        "\n",
        "    return report\n",
        "\n",
        "final_report = evaluate_transcript(sample_text, duration_sec=52)\n",
        "for criterion, details in final_report.items():\n",
        "    print(f\"{criterion}: {details}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiOrMsy4bfny",
        "outputId": "a5ef9019-c43a-428a-dbf2-87555eb67ecd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Salutation: {'score': 4, 'type': 'Good'}\n",
            "Keywords: {'score': 18, 'matched': ['class', 'school', 'family', 'interest', 'fun fact'], 'missing': ['name', 'age', 'hobbies', 'free time', 'about family', 'i am from', 'parents are from', 'ambition', 'goal', 'dream', 'unique', 'strength', 'achievement']}\n",
            "Flow: {'score': 5, 'feedback': 'Order followed'}\n",
            "Speech Rate: {'score': 6, 'wpm': 153.46, 'category': 'Fast'}\n",
            "Grammar: {'score': 10, 'errors': 0, 'ratio': 1.0}\n",
            "Vocabulary: {'score': 6, 'ttr': 0.68, 'category': 'Average'}\n",
            "Clarity: {'score': 15, 'fillers': 0, 'rate': 0.0, 'category': 'Excellent'}\n",
            "Engagement: {'score': 3, 'positivity': 0.19, 'category': 'Negative/Disengaged'}\n",
            "Total Score: 67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Streamlit Deployement**"
      ],
      "metadata": {
        "id": "0NVWJgXYcDpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "\n",
        "def run_app():\n",
        "    st.title(\"Communication Scoring Tool\")\n",
        "    st.write(\"Enter your introduction transcript below and get a detailed rubric-based score.\")\n",
        "\n",
        "    # User input text area\n",
        "    user_text = st.text_area(\"Type your transcript here:\", height=200)\n",
        "\n",
        "    # Duration input (seconds)\n",
        "    duration_sec = st.number_input(\"Enter speech duration (in seconds):\", min_value=1, value=60)\n",
        "\n",
        "    if st.button(\"Evaluate Transcript\"):\n",
        "        if user_text.strip():\n",
        "\n",
        "            report = evaluate_transcript(user_text, duration_sec)\n",
        "\n",
        "            st.subheader(\"ðŸ“Š Scoring Breakdown\")\n",
        "            for criterion, details in report.items():\n",
        "                st.write(f\"**{criterion}**: {details}\")\n",
        "\n",
        "            st.success(f\"âœ… Final Total Score: {report['Total Score']}\")\n",
        "        else:\n",
        "            st.warning(\"Please enter a transcript before evaluating.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_app()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvW9UpdBcXhb",
        "outputId": "15220e72-d437-4915-f511-4a5e1aaa974d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    }
  ]
}